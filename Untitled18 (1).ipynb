{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2769755-2fd7-4d84-92de-b50ed09013f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40378a12-7bc2-4000-a5c2-c50dfb7cc4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"C:/Users/aray28/Desktop/SOC_META/SOC_REQ.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db690d72-d337-49ed-9b84-bbd5ddf35898",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"SOC_lnRR\"]\n",
    "X = df.drop(columns=[\"SOC_lnRR\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "142ecfc0-9a56-4571-9a26-8cf9605dbd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.0803\n",
      "R² Score: 0.8095\n"
     ]
    }
   ],
   "source": [
    "# Define categorical and numerical features\n",
    "categorical_cols = [\"ClimateZone\", \"Soil_Type\", \"BIO_Type\", \"Treatment\", \"Crop_type\"]\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Define preprocessing pipelines\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))  # ✅ fixed argument\n",
    "])\n",
    "\n",
    "# Combine into ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_pipeline, numerical_cols),\n",
    "    (\"cat\", categorical_pipeline, categorical_cols)\n",
    "])\n",
    "\n",
    "# Build full pipeline with ExtraTreesRegressor\n",
    "model_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", ExtraTreesRegressor(n_estimators=300, random_state=42))\n",
    "])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cc44077-84ac-4631-ad7c-5964f51cc372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "from scipy.stats import randint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edd31f22-9143-4e52-b774-f090a1e290be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"C:/Users/aray28/Desktop/SOC_META/SOC_REQ.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea2d4311-d572-48b2-bb36-9a16ffaba0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"SOC_lnRR\"]\n",
    "X = df.drop(columns=[\"SOC_lnRR\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e91a5fe-d37b-4fe1-bd98-b4965d5202ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best Params: {'regressor__max_depth': 24, 'regressor__max_features': None, 'regressor__min_samples_leaf': 2, 'regressor__min_samples_split': 4, 'regressor__n_estimators': 414}\n",
      "MAE: 0.0792\n",
      "R² Score: 0.8215\n"
     ]
    }
   ],
   "source": [
    "# Define categorical and numerical features\n",
    "categorical_cols = [\"ClimateZone\", \"Soil_Type\", \"BIO_Type\", \"Treatment\", \"Crop_type\"]\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Preprocessing\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_pipeline, numerical_cols),\n",
    "    (\"cat\", categorical_pipeline, categorical_cols)\n",
    "])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Base model\n",
    "base_model = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", ExtraTreesRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_dist = {\n",
    "    \"regressor__n_estimators\": randint(200, 600),\n",
    "    \"regressor__max_depth\": [None] + list(range(5, 30)),\n",
    "    \"regressor__min_samples_split\": randint(2, 10),\n",
    "    \"regressor__min_samples_leaf\": randint(1, 6),\n",
    "    \"regressor__max_features\": ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Randomized search\n",
    "random_search = RandomizedSearchCV(\n",
    "    base_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    cv=5,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = random_search.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best Params: {random_search.best_params_}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcc8ad41-3599-48d3-ba91-6da50b47b01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 685\n",
      "[LightGBM] [Info] Number of data points in the train set: 639, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 0.282372\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Ensemble MAE: 0.0732\n",
      "Ensemble R²: 0.8551\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor, HistGradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Use best ExtraTrees params\n",
    "et_model = ExtraTreesRegressor(\n",
    "    n_estimators=414,\n",
    "    max_depth=24,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=2,\n",
    "    max_features=None,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# LightGBM\n",
    "lgbm_model = LGBMRegressor(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# CatBoost\n",
    "cat_model = CatBoostRegressor(\n",
    "    iterations=400,\n",
    "    depth=6,\n",
    "    learning_rate=0.05,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# HistGradientBoosting (optional alternative)\n",
    "hgb_model = HistGradientBoostingRegressor(\n",
    "    max_iter=400,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create Voting Regressor Ensemble\n",
    "ensemble_model = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", VotingRegressor(estimators=[\n",
    "        ('et', et_model),\n",
    "        ('lgbm', lgbm_model),\n",
    "        ('cat', cat_model)\n",
    "        # you can also add ('hgb', hgb_model) if needed\n",
    "    ]))\n",
    "])\n",
    "\n",
    "# Fit ensemble\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "y_pred_ens = ensemble_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mae = mean_absolute_error(y_test, y_pred_ens)\n",
    "r2 = r2_score(y_test, y_pred_ens)\n",
    "\n",
    "print(f\"Ensemble MAE: {mae:.4f}\")\n",
    "print(f\"Ensemble R²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7902bef4-23a9-4e1d-8f26-6702cf8f6acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d856362d-0a42-4fe1-8950-4c452bef9a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"C:/Users/aray28/Desktop/SOC_META/SOC_REQ.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57747b57-820a-41f5-95f8-d7a66bcbfd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"SOC_lnRR\"]\n",
    "X = df.drop(columns=[\"SOC_lnRR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45ef9263-ccdf-452f-8fdd-677d52824e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-13 14:32:28,210] A new study created in memory with name: ExtraTrees\n",
      "[I 2025-04-13 14:32:36,649] Trial 0 finished with value: 0.1729689886060612 and parameters: {'n_estimators': 490, 'max_depth': 29, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.1729689886060612.\n",
      "[I 2025-04-13 14:32:40,066] Trial 1 finished with value: 0.1595602290480327 and parameters: {'n_estimators': 145, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.1729689886060612.\n",
      "[I 2025-04-13 14:32:40,698] Trial 2 finished with value: 0.1561588020221879 and parameters: {'n_estimators': 165, 'max_depth': 18, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.1729689886060612.\n",
      "[I 2025-04-13 14:32:41,794] Trial 3 finished with value: 0.12925675719401716 and parameters: {'n_estimators': 460, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.1729689886060612.\n",
      "[I 2025-04-13 14:32:42,709] Trial 4 finished with value: 0.16225268557533612 and parameters: {'n_estimators': 288, 'max_depth': 24, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.1729689886060612.\n",
      "[I 2025-04-13 14:32:43,432] Trial 5 finished with value: 0.183785671161883 and parameters: {'n_estimators': 313, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.183785671161883.\n",
      "[I 2025-04-13 14:32:43,811] Trial 6 finished with value: 0.17954374735342107 and parameters: {'n_estimators': 205, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.183785671161883.\n",
      "[I 2025-04-13 14:32:44,137] Trial 7 finished with value: 0.12207041636460259 and parameters: {'n_estimators': 153, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 5 with value: 0.183785671161883.\n",
      "[I 2025-04-13 14:32:45,130] Trial 8 finished with value: 0.16614657569441854 and parameters: {'n_estimators': 383, 'max_depth': 11, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 5 with value: 0.183785671161883.\n",
      "[I 2025-04-13 14:32:46,394] Trial 9 finished with value: 0.16833274922869873 and parameters: {'n_estimators': 472, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 5 with value: 0.183785671161883.\n",
      "[I 2025-04-13 14:32:47,421] Trial 10 finished with value: 0.17923512668886632 and parameters: {'n_estimators': 313, 'max_depth': 18, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.183785671161883.\n",
      "[I 2025-04-13 14:32:47,955] Trial 11 finished with value: 0.18164987630277987 and parameters: {'n_estimators': 248, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.183785671161883.\n",
      "[I 2025-04-13 14:32:48,562] Trial 12 finished with value: 0.18192865320387225 and parameters: {'n_estimators': 265, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.183785671161883.\n",
      "[I 2025-04-13 14:32:49,682] Trial 13 finished with value: 0.17288804526818946 and parameters: {'n_estimators': 366, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.183785671161883.\n",
      "[I 2025-04-13 14:32:50,764] Trial 14 finished with value: 0.1498605338163158 and parameters: {'n_estimators': 344, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 5 with value: 0.183785671161883.\n",
      "[I 2025-04-13 14:32:51,374] Trial 15 finished with value: 0.18147904593434644 and parameters: {'n_estimators': 246, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.183785671161883.\n",
      "[I 2025-04-13 14:32:52,237] Trial 16 finished with value: 0.16900877531176028 and parameters: {'n_estimators': 265, 'max_depth': 22, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.183785671161883.\n",
      "[I 2025-04-13 14:32:53,510] Trial 17 finished with value: 0.15329415834984925 and parameters: {'n_estimators': 411, 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 5 with value: 0.183785671161883.\n",
      "[I 2025-04-13 14:32:54,051] Trial 18 finished with value: 0.18801422467721993 and parameters: {'n_estimators': 207, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 18 with value: 0.18801422467721993.\n",
      "[I 2025-04-13 14:32:54,630] Trial 19 finished with value: 0.18162004583031358 and parameters: {'n_estimators': 203, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 18 with value: 0.18801422467721993.\n",
      "[I 2025-04-13 14:32:55,330] Trial 20 finished with value: 0.17584542177937565 and parameters: {'n_estimators': 214, 'max_depth': 21, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 18 with value: 0.18801422467721993.\n",
      "[I 2025-04-13 14:32:55,956] Trial 21 finished with value: 0.18340664929389622 and parameters: {'n_estimators': 313, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 18 with value: 0.18801422467721993.\n",
      "[I 2025-04-13 14:32:56,255] Trial 22 finished with value: 0.17689641707236842 and parameters: {'n_estimators': 101, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 18 with value: 0.18801422467721993.\n",
      "[I 2025-04-13 14:32:57,086] Trial 23 finished with value: 0.1698693451202508 and parameters: {'n_estimators': 323, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 18 with value: 0.18801422467721993.\n",
      "[I 2025-04-13 14:32:58,247] Trial 24 finished with value: 0.17842076064370055 and parameters: {'n_estimators': 420, 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 18 with value: 0.18801422467721993.\n",
      "[I 2025-04-13 14:32:58,880] Trial 25 finished with value: 0.18551975370798843 and parameters: {'n_estimators': 294, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 18 with value: 0.18801422467721993.\n",
      "[I 2025-04-13 14:32:59,518] Trial 26 finished with value: 0.18367557576487972 and parameters: {'n_estimators': 287, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 18 with value: 0.18801422467721993.\n",
      "[I 2025-04-13 14:33:00,479] Trial 27 finished with value: 0.16534465396412723 and parameters: {'n_estimators': 345, 'max_depth': 13, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 18 with value: 0.18801422467721993.\n",
      "[I 2025-04-13 14:33:01,206] Trial 28 finished with value: 0.1735995572558912 and parameters: {'n_estimators': 232, 'max_depth': 15, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 18 with value: 0.18801422467721993.\n",
      "[I 2025-04-13 14:33:01,646] Trial 29 finished with value: 0.1794976624911748 and parameters: {'n_estimators': 179, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 18 with value: 0.18801422467721993.\n",
      "[I 2025-04-13 14:33:01,647] A new study created in memory with name: LGBM\n",
      "[I 2025-04-13 14:33:07,518] Trial 0 finished with value: 0.03304996634080275 and parameters: {'n_estimators': 251, 'max_depth': 10, 'num_leaves': 46, 'learning_rate': 0.22658783012209344, 'subsample': 0.9527064773214295, 'colsample_bytree': 0.6161270900535171}. Best is trial 0 with value: 0.03304996634080275.\n",
      "[I 2025-04-13 14:33:11,356] Trial 1 finished with value: 0.008229936507613144 and parameters: {'n_estimators': 420, 'max_depth': 30, 'num_leaves': 113, 'learning_rate': 0.07991661115295405, 'subsample': 0.7270784134388666, 'colsample_bytree': 0.7608236946426832}. Best is trial 0 with value: 0.03304996634080275.\n",
      "[I 2025-04-13 14:33:12,174] Trial 2 finished with value: -0.06582857902858859 and parameters: {'n_estimators': 228, 'max_depth': 24, 'num_leaves': 122, 'learning_rate': 0.2767670955239117, 'subsample': 0.5676189039660957, 'colsample_bytree': 0.918751437432952}. Best is trial 0 with value: 0.03304996634080275.\n",
      "[I 2025-04-13 14:33:12,878] Trial 3 finished with value: -0.004335193303967699 and parameters: {'n_estimators': 442, 'max_depth': 5, 'num_leaves': 54, 'learning_rate': 0.16938442761968184, 'subsample': 0.8202072636603595, 'colsample_bytree': 0.9272795115879104}. Best is trial 0 with value: 0.03304996634080275.\n",
      "[I 2025-04-13 14:33:13,641] Trial 4 finished with value: -0.02096170324489526 and parameters: {'n_estimators': 260, 'max_depth': 16, 'num_leaves': 148, 'learning_rate': 0.14554719649359762, 'subsample': 0.9984630771529934, 'colsample_bytree': 0.8030362971799578}. Best is trial 0 with value: 0.03304996634080275.\n",
      "[I 2025-04-13 14:33:14,323] Trial 5 finished with value: 0.03677402796602451 and parameters: {'n_estimators': 230, 'max_depth': 14, 'num_leaves': 130, 'learning_rate': 0.07147530325854567, 'subsample': 0.5695377267380332, 'colsample_bytree': 0.650859571426806}. Best is trial 5 with value: 0.03677402796602451.\n",
      "[I 2025-04-13 14:33:15,366] Trial 6 finished with value: 0.02988396434668248 and parameters: {'n_estimators': 361, 'max_depth': 29, 'num_leaves': 62, 'learning_rate': 0.11504301756715994, 'subsample': 0.8220163528091768, 'colsample_bytree': 0.8423534132029827}. Best is trial 5 with value: 0.03677402796602451.\n",
      "[I 2025-04-13 14:33:15,905] Trial 7 finished with value: -0.008131784675845587 and parameters: {'n_estimators': 167, 'max_depth': 16, 'num_leaves': 43, 'learning_rate': 0.09652596536760988, 'subsample': 0.983696614890095, 'colsample_bytree': 0.699734782701805}. Best is trial 5 with value: 0.03677402796602451.\n",
      "[I 2025-04-13 14:33:16,637] Trial 8 finished with value: 0.04979457105651397 and parameters: {'n_estimators': 220, 'max_depth': 18, 'num_leaves': 139, 'learning_rate': 0.04085856498958385, 'subsample': 0.6794370833628256, 'colsample_bytree': 0.6944265586858844}. Best is trial 8 with value: 0.04979457105651397.\n",
      "[I 2025-04-13 14:33:17,221] Trial 9 finished with value: 0.01395166781676438 and parameters: {'n_estimators': 144, 'max_depth': 21, 'num_leaves': 102, 'learning_rate': 0.1621692275067404, 'subsample': 0.8583710364685359, 'colsample_bytree': 0.9967347658221456}. Best is trial 8 with value: 0.04979457105651397.\n",
      "[I 2025-04-13 14:33:18,571] Trial 10 finished with value: 0.1383727487284921 and parameters: {'n_estimators': 340, 'max_depth': 22, 'num_leaves': 76, 'learning_rate': 0.011731113604184357, 'subsample': 0.6738452609604628, 'colsample_bytree': 0.5155889110160901}. Best is trial 10 with value: 0.1383727487284921.\n",
      "[I 2025-04-13 14:33:19,811] Trial 11 finished with value: 0.1485320202039074 and parameters: {'n_estimators': 318, 'max_depth': 21, 'num_leaves': 83, 'learning_rate': 0.010259675860639727, 'subsample': 0.6796568574188429, 'colsample_bytree': 0.5133849702171432}. Best is trial 11 with value: 0.1485320202039074.\n",
      "[I 2025-04-13 14:33:21,154] Trial 12 finished with value: 0.13155340033338475 and parameters: {'n_estimators': 362, 'max_depth': 24, 'num_leaves': 81, 'learning_rate': 0.010641340303103075, 'subsample': 0.6529706497644698, 'colsample_bytree': 0.517099302556723}. Best is trial 11 with value: 0.1485320202039074.\n",
      "[I 2025-04-13 14:33:22,187] Trial 13 finished with value: 0.13605897864584096 and parameters: {'n_estimators': 333, 'max_depth': 24, 'num_leaves': 21, 'learning_rate': 0.012930585819051654, 'subsample': 0.6400433614473847, 'colsample_bytree': 0.5213685483112058}. Best is trial 11 with value: 0.1485320202039074.\n",
      "[I 2025-04-13 14:33:23,734] Trial 14 finished with value: 0.024502826019650037 and parameters: {'n_estimators': 485, 'max_depth': 20, 'num_leaves': 86, 'learning_rate': 0.05732555794891766, 'subsample': 0.5007920431618815, 'colsample_bytree': 0.5773867066869626}. Best is trial 11 with value: 0.1485320202039074.\n",
      "[I 2025-04-13 14:33:24,587] Trial 15 finished with value: 0.06798201868391551 and parameters: {'n_estimators': 307, 'max_depth': 26, 'num_leaves': 83, 'learning_rate': 0.03820424576049433, 'subsample': 0.7463842468812816, 'colsample_bytree': 0.566282546109299}. Best is trial 11 with value: 0.1485320202039074.\n",
      "[I 2025-04-13 14:33:25,831] Trial 16 finished with value: 0.018571545607554186 and parameters: {'n_estimators': 409, 'max_depth': 12, 'num_leaves': 69, 'learning_rate': 0.20501531641674237, 'subsample': 0.5935206582592348, 'colsample_bytree': 0.5837261698424155}. Best is trial 11 with value: 0.1485320202039074.\n",
      "[I 2025-04-13 14:33:26,773] Trial 17 finished with value: 0.028381911772678327 and parameters: {'n_estimators': 301, 'max_depth': 21, 'num_leaves': 100, 'learning_rate': 0.12030011044100239, 'subsample': 0.6976416783391051, 'colsample_bytree': 0.510542507261129}. Best is trial 11 with value: 0.1485320202039074.\n",
      "[I 2025-04-13 14:33:27,782] Trial 18 finished with value: -0.0036528259298261867 and parameters: {'n_estimators': 375, 'max_depth': 27, 'num_leaves': 27, 'learning_rate': 0.293474107175051, 'subsample': 0.7972471308633375, 'colsample_bytree': 0.678848965431968}. Best is trial 11 with value: 0.1485320202039074.\n",
      "[I 2025-04-13 14:33:29,206] Trial 19 finished with value: 0.0730512854673226 and parameters: {'n_estimators': 490, 'max_depth': 19, 'num_leaves': 72, 'learning_rate': 0.03298584490832118, 'subsample': 0.619213241621204, 'colsample_bytree': 0.6313588727260792}. Best is trial 11 with value: 0.1485320202039074.\n",
      "[I 2025-04-13 14:33:29,796] Trial 20 finished with value: 0.03088185525944962 and parameters: {'n_estimators': 178, 'max_depth': 22, 'num_leaves': 98, 'learning_rate': 0.0920940283770138, 'subsample': 0.8899561166093637, 'colsample_bytree': 0.7405710492566533}. Best is trial 11 with value: 0.1485320202039074.\n",
      "[I 2025-04-13 14:33:30,698] Trial 21 finished with value: 0.1426081031632761 and parameters: {'n_estimators': 313, 'max_depth': 24, 'num_leaves': 20, 'learning_rate': 0.010718459821250208, 'subsample': 0.6371797912469559, 'colsample_bytree': 0.5337102637173681}. Best is trial 11 with value: 0.1485320202039074.\n",
      "[I 2025-04-13 14:33:31,631] Trial 22 finished with value: 0.13788166691301387 and parameters: {'n_estimators': 280, 'max_depth': 26, 'num_leaves': 34, 'learning_rate': 0.015028439676387943, 'subsample': 0.6970805379689989, 'colsample_bytree': 0.5528605530853642}. Best is trial 11 with value: 0.1485320202039074.\n",
      "[I 2025-04-13 14:33:33,127] Trial 23 finished with value: 0.03943534098320558 and parameters: {'n_estimators': 391, 'max_depth': 23, 'num_leaves': 57, 'learning_rate': 0.05696714305953242, 'subsample': 0.7714190006524989, 'colsample_bytree': 0.5030079522442503}. Best is trial 11 with value: 0.1485320202039074.\n",
      "[I 2025-04-13 14:33:34,530] Trial 24 finished with value: 0.04540885232773466 and parameters: {'n_estimators': 329, 'max_depth': 28, 'num_leaves': 90, 'learning_rate': 0.03829229580197188, 'subsample': 0.5161971229410447, 'colsample_bytree': 0.604283460112953}. Best is trial 11 with value: 0.1485320202039074.\n",
      "[I 2025-04-13 14:33:35,802] Trial 25 finished with value: 0.03189393184993321 and parameters: {'n_estimators': 333, 'max_depth': 17, 'num_leaves': 113, 'learning_rate': 0.05490981212182816, 'subsample': 0.6685981388384973, 'colsample_bytree': 0.5443555537135956}. Best is trial 11 with value: 0.1485320202039074.\n",
      "[I 2025-04-13 14:33:37,019] Trial 26 finished with value: 0.09454708022730159 and parameters: {'n_estimators': 283, 'max_depth': 25, 'num_leaves': 71, 'learning_rate': 0.029121401009682916, 'subsample': 0.608679055344661, 'colsample_bytree': 0.5517752495506203}. Best is trial 11 with value: 0.1485320202039074.\n",
      "[I 2025-04-13 14:33:38,117] Trial 27 finished with value: 0.013993857279802957 and parameters: {'n_estimators': 335, 'max_depth': 19, 'num_leaves': 43, 'learning_rate': 0.07070778628121159, 'subsample': 0.7281496044364602, 'colsample_bytree': 0.5997499976549123}. Best is trial 11 with value: 0.1485320202039074.\n",
      "[I 2025-04-13 14:33:38,498] Trial 28 finished with value: 0.0214153699240343 and parameters: {'n_estimators': 101, 'max_depth': 21, 'num_leaves': 33, 'learning_rate': 0.11629696350852384, 'subsample': 0.550610321969197, 'colsample_bytree': 0.631696073185947}. Best is trial 11 with value: 0.1485320202039074.\n",
      "[I 2025-04-13 14:33:39,105] Trial 29 finished with value: -0.05824873321653725 and parameters: {'n_estimators': 266, 'max_depth': 7, 'num_leaves': 55, 'learning_rate': 0.23219327796351724, 'subsample': 0.7055122663740252, 'colsample_bytree': 0.6623422812641466}. Best is trial 11 with value: 0.1485320202039074.\n",
      "[I 2025-04-13 14:33:39,105] A new study created in memory with name: CatBoost\n",
      "[I 2025-04-13 14:33:44,942] Trial 0 finished with value: 0.11194722037792433 and parameters: {'iterations': 428, 'depth': 5, 'learning_rate': 0.18449981203429505, 'l2_leaf_reg': 5.736399680853086}. Best is trial 0 with value: 0.11194722037792433.\n",
      "[I 2025-04-13 14:33:47,777] Trial 1 finished with value: 0.20013728365139755 and parameters: {'iterations': 233, 'depth': 7, 'learning_rate': 0.2661936925785558, 'l2_leaf_reg': 2.14690636266171}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:33:54,244] Trial 2 finished with value: 0.11701528326205994 and parameters: {'iterations': 236, 'depth': 10, 'learning_rate': 0.27748448353527416, 'l2_leaf_reg': 7.984665754069865}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:33:55,068] Trial 3 finished with value: 0.18568052438250987 and parameters: {'iterations': 201, 'depth': 6, 'learning_rate': 0.14228542114723283, 'l2_leaf_reg': 2.2090077243751702}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:33:56,767] Trial 4 finished with value: 0.13875346304242556 and parameters: {'iterations': 455, 'depth': 6, 'learning_rate': 0.18164519646784882, 'l2_leaf_reg': 3.7684288297908486}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:33:59,501] Trial 5 finished with value: 0.1661404624970741 and parameters: {'iterations': 332, 'depth': 8, 'learning_rate': 0.13167739674071918, 'l2_leaf_reg': 7.285446223360193}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:33:59,926] Trial 6 finished with value: 0.14735694645486003 and parameters: {'iterations': 124, 'depth': 5, 'learning_rate': 0.0847038983321964, 'l2_leaf_reg': 9.35694191564302}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:34:00,564] Trial 7 finished with value: 0.10733292961095778 and parameters: {'iterations': 181, 'depth': 6, 'learning_rate': 0.17439108031044576, 'l2_leaf_reg': 8.236903899536927}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:34:01,761] Trial 8 finished with value: 0.1225145195970034 and parameters: {'iterations': 165, 'depth': 8, 'learning_rate': 0.2776093826520271, 'l2_leaf_reg': 6.928060417679862}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:34:02,349] Trial 9 finished with value: 0.06263709425453452 and parameters: {'iterations': 320, 'depth': 4, 'learning_rate': 0.16448444550584007, 'l2_leaf_reg': 5.782090973607669}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:34:09,563] Trial 10 finished with value: 0.17474164425195604 and parameters: {'iterations': 267, 'depth': 10, 'learning_rate': 0.010283175983557602, 'l2_leaf_reg': 1.131846596444574}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:34:10,738] Trial 11 finished with value: 0.11853263886326329 and parameters: {'iterations': 215, 'depth': 7, 'learning_rate': 0.2334156830519523, 'l2_leaf_reg': 2.1185066732257556}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:34:11,663] Trial 12 finished with value: 0.17735900058970436 and parameters: {'iterations': 101, 'depth': 8, 'learning_rate': 0.09514489283059643, 'l2_leaf_reg': 3.6259112072488704}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:34:13,542] Trial 13 finished with value: 0.1440209711087115 and parameters: {'iterations': 374, 'depth': 7, 'learning_rate': 0.22260891725899234, 'l2_leaf_reg': 3.2421648167773536}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:34:14,634] Trial 14 finished with value: 0.1261964235607294 and parameters: {'iterations': 275, 'depth': 6, 'learning_rate': 0.11520079660048545, 'l2_leaf_reg': 1.1413364164843316}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:34:17,227] Trial 15 finished with value: 0.1704488026359003 and parameters: {'iterations': 200, 'depth': 9, 'learning_rate': 0.035426562549344814, 'l2_leaf_reg': 2.5606583684623163}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:34:17,610] Trial 16 finished with value: 0.1103193882088461 and parameters: {'iterations': 163, 'depth': 4, 'learning_rate': 0.2286203484620577, 'l2_leaf_reg': 4.654717719747362}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:34:18,491] Trial 17 finished with value: 0.11828195111332702 and parameters: {'iterations': 366, 'depth': 5, 'learning_rate': 0.06567780182649534, 'l2_leaf_reg': 2.153195248603631}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:34:19,635] Trial 18 finished with value: 0.13776528298893 and parameters: {'iterations': 245, 'depth': 7, 'learning_rate': 0.13981817323820928, 'l2_leaf_reg': 4.724500462104707}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:34:21,010] Trial 19 finished with value: 0.1833907609066453 and parameters: {'iterations': 287, 'depth': 7, 'learning_rate': 0.2981555050257442, 'l2_leaf_reg': 2.841369859364808}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:34:23,106] Trial 20 finished with value: 0.06846276087834116 and parameters: {'iterations': 145, 'depth': 9, 'learning_rate': 0.20457601246668794, 'l2_leaf_reg': 4.489271722722201}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:34:24,253] Trial 21 finished with value: 0.05089280458606291 and parameters: {'iterations': 276, 'depth': 6, 'learning_rate': 0.2992320874268252, 'l2_leaf_reg': 2.717091324019426}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:34:25,489] Trial 22 finished with value: 0.19052628721909853 and parameters: {'iterations': 226, 'depth': 7, 'learning_rate': 0.2622498950688701, 'l2_leaf_reg': 1.5700984963344744}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:34:26,753] Trial 23 finished with value: 0.16077634669211158 and parameters: {'iterations': 233, 'depth': 7, 'learning_rate': 0.2620218089699392, 'l2_leaf_reg': 1.7203230048271534}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:34:28,470] Trial 24 finished with value: 0.1982711745448519 and parameters: {'iterations': 203, 'depth': 8, 'learning_rate': 0.24678259755327547, 'l2_leaf_reg': 1.1098882208378422}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:34:32,559] Trial 25 finished with value: 0.17904796754401686 and parameters: {'iterations': 321, 'depth': 9, 'learning_rate': 0.24717529482818595, 'l2_leaf_reg': 1.2225933198214032}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:34:36,031] Trial 26 finished with value: 0.17603140250097368 and parameters: {'iterations': 498, 'depth': 8, 'learning_rate': 0.20788684048055633, 'l2_leaf_reg': 1.6595455236477576}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:34:37,993] Trial 27 finished with value: 0.1660664759214528 and parameters: {'iterations': 247, 'depth': 8, 'learning_rate': 0.278233836554626, 'l2_leaf_reg': 3.9283630768685995}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:34:40,782] Trial 28 finished with value: 0.19650448384764074 and parameters: {'iterations': 188, 'depth': 9, 'learning_rate': 0.2541224026432253, 'l2_leaf_reg': 3.1932242801360315}. Best is trial 1 with value: 0.20013728365139755.\n",
      "[I 2025-04-13 14:34:42,659] Trial 29 finished with value: 0.12995942012830877 and parameters: {'iterations': 130, 'depth': 9, 'learning_rate': 0.2057774501596937, 'l2_leaf_reg': 5.914673849556649}. Best is trial 1 with value: 0.20013728365139755.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ExtraTrees Best Params: {'n_estimators': 207, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 3}\n",
      "✅ LGBM Best Params: {'n_estimators': 318, 'max_depth': 21, 'num_leaves': 83, 'learning_rate': 0.010259675860639727, 'subsample': 0.6796568574188429, 'colsample_bytree': 0.5133849702171432}\n",
      "✅ CatBoost Best Params: {'iterations': 233, 'depth': 7, 'learning_rate': 0.2661936925785558, 'l2_leaf_reg': 2.14690636266171}\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = [\"ClimateZone\", \"Soil_Type\", \"BIO_Type\", \"Crop_type\"]\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Fill missing values\n",
    "X[categorical_cols] = X[categorical_cols].fillna(\"Missing\")\n",
    "for col in numerical_cols:\n",
    "    X[col] = pd.to_numeric(X[col], errors=\"coerce\")\n",
    "    X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "# Preprocessing pipeline\n",
    "numeric_pipeline = Pipeline([(\"imputer\", SimpleImputer(strategy=\"mean\"))])\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_pipeline, numerical_cols),\n",
    "    (\"cat\", categorical_pipeline, categorical_cols)\n",
    "])\n",
    "\n",
    "def tune_model(trial, model_name):\n",
    "    if model_name == \"ExtraTrees\":\n",
    "        model = ExtraTreesRegressor(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "            max_depth=trial.suggest_int(\"max_depth\", 5, 30),\n",
    "            min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "            min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    elif model_name == \"LGBM\":\n",
    "        model = LGBMRegressor(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "            max_depth=trial.suggest_int(\"max_depth\", 5, 30),\n",
    "            num_leaves=trial.suggest_int(\"num_leaves\", 20, 150),\n",
    "            learning_rate=trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "            subsample=trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    elif model_name == \"CatBoost\":\n",
    "        model = CatBoostRegressor(\n",
    "            iterations=trial.suggest_int(\"iterations\", 100, 500),\n",
    "            depth=trial.suggest_int(\"depth\", 4, 10),\n",
    "            learning_rate=trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "            l2_leaf_reg=trial.suggest_float(\"l2_leaf_reg\", 1, 10),\n",
    "            verbose=0,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"regressor\", model)\n",
    "    ])\n",
    "    score = cross_val_score(pipeline, X, y, scoring=\"r2\", cv=5, n_jobs=-1)\n",
    "    return score.mean()\n",
    "\n",
    "# Tune all models\n",
    "study_et = optuna.create_study(direction=\"maximize\", study_name=\"ExtraTrees\")\n",
    "study_et.optimize(lambda trial: tune_model(trial, \"ExtraTrees\"), n_trials=30)\n",
    "\n",
    "study_lgbm = optuna.create_study(direction=\"maximize\", study_name=\"LGBM\")\n",
    "study_lgbm.optimize(lambda trial: tune_model(trial, \"LGBM\"), n_trials=30)\n",
    "\n",
    "study_cat = optuna.create_study(direction=\"maximize\", study_name=\"CatBoost\")\n",
    "study_cat.optimize(lambda trial: tune_model(trial, \"CatBoost\"), n_trials=30)\n",
    "\n",
    "print(\"✅ ExtraTrees Best Params:\", study_et.best_params)\n",
    "print(\"✅ LGBM Best Params:\", study_lgbm.best_params)\n",
    "print(\"✅ CatBoost Best Params:\", study_cat.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbe7b31e-ba89-4d61-85f6-040abc9290e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aray28\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:577: UserWarning: Skipping features without any observed values: ['Treatment']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Ensemble MAE: 0.0805\n",
      "✅ Ensemble R²: 0.8106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aray28\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:577: UserWarning: Skipping features without any observed values: ['Treatment']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor, StackingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# === 1. Load Data ===\n",
    "df = pd.read_excel(\"C:/Users/aray28/Desktop/SOC_META/SOC_REQ.xlsx\")\n",
    "y = df[\"SOC_lnRR\"]\n",
    "X = df.drop(columns=[\"SOC_lnRR\"])\n",
    "\n",
    "# === 2. Define Categorical Columns ===\n",
    "categorical_cols = [\"ClimateZone\", \"Soil_Type\", \"BIO_Type\", \"Crop_type\"]\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Fill missing values\n",
    "X[categorical_cols] = X[categorical_cols].fillna(\"Missing\")\n",
    "for col in numerical_cols:\n",
    "    X[col] = pd.to_numeric(X[col], errors=\"coerce\")\n",
    "    X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "\n",
    "# Fill missing values\n",
    "X[categorical_cols] = X[categorical_cols].fillna(\"Missing\")\n",
    "for col in numerical_cols:\n",
    "    X[col] = pd.to_numeric(X[col], errors=\"coerce\")\n",
    "    X[col] = X[col].fillna(X[col].median())\n",
    "    \n",
    "# === 4. Preprocessing Pipeline ===\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_pipeline, numerical_cols),\n",
    "    (\"cat\", categorical_pipeline, categorical_cols)\n",
    "])\n",
    "\n",
    "# === 5. Define Tuned Base Models ===\n",
    "et_model = ExtraTreesRegressor(\n",
    "    n_estimators=207,\n",
    "    max_depth=7,\n",
    "    min_samples_split=7,\n",
    "    min_samples_leaf=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgbm_model = LGBMRegressor(\n",
    "    n_estimators=318,\n",
    "    max_depth=21,\n",
    "    num_leaves=83,\n",
    "    learning_rate=0.01026,\n",
    "    subsample=0.6796,\n",
    "    colsample_bytree=0.5133,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "cat_model = CatBoostRegressor(\n",
    "    iterations=233,\n",
    "    depth=7,\n",
    "    learning_rate=0.2661,\n",
    "    l2_leaf_reg=2.1469,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# === 6. Stacking Ensemble ===\n",
    "ensemble_model = StackingRegressor(\n",
    "    estimators=[\n",
    "        (\"et\", et_model),\n",
    "        (\"lgbm\", lgbm_model),\n",
    "        (\"cat\", cat_model)\n",
    "    ],\n",
    "    final_estimator=ExtraTreesRegressor(n_estimators=100, random_state=42),\n",
    "    passthrough=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# === 7. Full Pipeline ===\n",
    "model_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", ensemble_model)\n",
    "])\n",
    "\n",
    "# === 8. Train/Test Split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# === 9. Fit and Predict ===\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# === 10. Evaluation ===\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"🔍 Ensemble MAE: {mae:.4f}\")\n",
    "print(f\"✅ Ensemble R²: {r2:.4f}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfd5e166-067b-4c8d-9d78-7464210eee67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aray28\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:577: UserWarning: Skipping features without any observed values: ['Treatment']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Stacked Regressor MAE: 0.0805\n",
      "✅ Stacked Regressor R²: 0.8106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aray28\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:577: UserWarning: Skipping features without any observed values: ['Treatment']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor, StackingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# === Load Data ===\n",
    "# === 1. Load Data ===\n",
    "df = pd.read_excel(\"C:/Users/aray28/Desktop/SOC_META/SOC_REQ.xlsx\")\n",
    "y = df[\"SOC_lnRR\"]\n",
    "X = df.drop(columns=[\"SOC_lnRR\"])\n",
    "\n",
    "# === 2. Define Categorical Columns ===\n",
    "categorical_cols = [\"ClimateZone\", \"Soil_Type\", \"BIO_Type\", \"Crop_type\"]\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# Fill missing values\n",
    "X[categorical_cols] = X[categorical_cols].fillna(\"Missing\")\n",
    "for col in numerical_cols:\n",
    "    X[col] = pd.to_numeric(X[col], errors=\"coerce\")\n",
    "    X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "# === Preprocessing Pipelines ===\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_pipeline, numerical_cols),\n",
    "    (\"cat\", categorical_pipeline, categorical_cols)\n",
    "])\n",
    "\n",
    "# === Base Models with Optuna-Tuned Parameters ===\n",
    "et_model = ExtraTreesRegressor(\n",
    "    n_estimators=207,\n",
    "    max_depth=7,\n",
    "    min_samples_split=7,\n",
    "    min_samples_leaf=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgbm_model = LGBMRegressor(\n",
    "    n_estimators=318,\n",
    "    max_depth=21,\n",
    "    num_leaves=83,\n",
    "    learning_rate=0.01026,\n",
    "    subsample=0.6796,\n",
    "    colsample_bytree=0.5133,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "cat_model = CatBoostRegressor(\n",
    "    iterations=233,\n",
    "    depth=7,\n",
    "    learning_rate=0.2661,\n",
    "    l2_leaf_reg=2.1469,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# === Stacking Regressor ===\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('et', et_model),\n",
    "        ('lgbm', lgbm_model),\n",
    "        ('cat', cat_model)\n",
    "    ],\n",
    "    final_estimator=ExtraTreesRegressor(n_estimators=100, random_state=42),\n",
    "    passthrough=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# === Full Pipeline ===\n",
    "stack_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", stacking_model)\n",
    "])\n",
    "\n",
    "# === Train/Test Split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# === Train Model ===\n",
    "stack_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# === Predict & Evaluate ===\n",
    "y_pred = stack_pipeline.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"📊 Stacked Regressor MAE: {mae:.4f}\")\n",
    "print(f\"✅ Stacked Regressor R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7e3b44-494e-4152-9231-b87bd2a266e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
